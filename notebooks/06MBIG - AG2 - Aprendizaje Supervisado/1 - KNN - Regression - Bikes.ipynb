{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1 - KNN - Regression - Bikes.ipynb","provenance":[{"file_id":"1t2_gCaPq0n8IBy97O8HMmiHDGh_wXmOO","timestamp":1521481985334}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OJFRKa5M41ok"},"source":["# El problema\n","\n","Una empresa de bicicletas compartidas que opera en el área de una ciudad específica. tiene un esquema de funcionamiento en el cual los usuarios pueden alquilar una bicicleta desde un lugar en particular y devolverla en un lugar diferente utilizando su infraestructura.\n","\n","El problema consiste en predecir cuántas bicicletas se van a utilizar en el futuro. Para ello se nos facilita un archivo  [csv](https://drive.google.com/open?id=1gTcb3WZ27DU0nMdvoyPBMYRFK8LU8-rt) donde aparecen el número de bicicletas contratadas todos los días y las variables metereológicas de esos días.\n","\n","Se usará análisis de regresión con el fin de capturar la relación entre características y número de bicicletas contratadas en un modelo.\n","\n","\n","# 0. Carga de Datos\n","\n","Cargaremos los datos de la misma forma que lo hemos hecho otras veces en Google Collaboratory.\n"]},{"cell_type":"code","metadata":{"id":"pp9tjdSA6rR5"},"source":["# 0. load data from file\n","from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8tye7Kut6vPB"},"source":["Posteriomente lo cargamos en un DataFrame de Pandas con el nombre de *bikes*"]},{"cell_type":"code","metadata":{"id":"rxVQ7L5c4B-x"},"source":["# 0. load data in DataFrame\n","import pandas as pd\n","import io\n","bikes = pd.read_csv(io.StringIO(uploaded[fn].decode('utf-8')), \n","                    index_col = 'date')\n","bikes.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zS0Cx6QvlH2"},"source":["bikes.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYla6oegmq8c"},"source":["bikes.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgqhRy5Fmu5N"},"source":["bikes.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qw1rvr-v5dy5"},"source":["Posteriormente seleccionamos las variables con las que trabajar. \n","\n","Es muy importante seleccionar las características cuando se va a resolver un problema mediante kNN ya que muchas variables pueden distorsionar el resultado del algoritmo que está basado en la distancia. \n","\n","Para realizar esta selección vamos a utilizar la correlación entre cada una de las características y la variable a predecir.\n","\n"]},{"cell_type":"code","metadata":{"id":"ec6UrovRcDv4"},"source":["import seaborn as sns\n","\n","sns.set()\n","sns.heatmap(bikes.corr(), square=True, annot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-T6SmVPcAMW"},"source":["En este caso de entre las tres posibles, seleccionamos aquellas que previamente mediante análisis de correlaciones, y o análisis mediante árboles de decisión o random forests nos han dado un valor superior.\n","\n","Además vamos a dividir nuestro conjunto de datos en dos partes una para entrenamiento (tuning) y otra para test. Para ello vamos a utilizar los datos de 2011 y la mitad de 2012 para entrenamiento y el resto de 2012 para los tests.  "]},{"cell_type":"code","metadata":{"id":"68vRdHb95ZUC"},"source":["# 0.1 features and labels\n","df = bikes[['temperature', 'humidity', 'count']]\n","\n","train = df.loc['2011-01-01':'2012-06-30']\n","test  = df.loc['2012-07-01':]\n","\n","test.head()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7NjZheI7Bhr"},"source":["#1. Parametrización\n","\n","Existen diferentes parámetros para método basado en los vecinos más cercanos utilizando scikit-learn\n","\n","\n","\n","*   **KNeighbors/Radius**: KNeihgbors está basado en el estudio de los k vecinos más cercanos para cada punto, mientras que RadiusNeighboors están basados en un conjunto de vecinos que están dentro de un radio. **Nuestra elección es la primera**, la segunda sería útil cuando los datos no estuvieran muestreados de forma uniforme.\n","* **K/Radio**\n","    * k: Un número k mayor suprime el eecto del ruido pero hace a los límites de clasificación más distintos.\n","    * Radios, un radio fijo es muy adecuado cuando los datos están muy dispersos (sparse neighbours)\n","*   **Pesos** : dos posibles valores, \"uniform\" cada vecino tiene el mismo peso, \"distance\" se asigna un peso a cada vecino proporcional a la distancia que esté del elemento referencia. También se puede definir una dfunción por parte del usuario\n","\n","Nuestra elección KNeighbors y k y pesos se van a parametrizar para ello se ejecutará [validación cruzada]([https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada) y como medida de éxito vamos a utilizar [MAE](https://es.wikipedia.org/wiki/Valor_absoluto)\n"]},{"cell_type":"code","metadata":{"id":"ZW1Ul7wStKuM"},"source":["# reseteamos el index con el fin de evitar problemas en la validación cruzada\n","train.reset_index(drop = True, inplace = True)\n","train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCfTgNtbfFDG"},"source":["from sklearn import neighbors\n","from sklearn.model_selection import KFold\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_absolute_error\n","import numpy as np\n","\n","cv = KFold(n_splits = 10, shuffle = False) #\n","# se podría utilizar https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html \n","\n","\n","for i, weights in enumerate(['uniform', 'distance']):\n","   total_scores = []\n","   for n_neighbors in range(1,30):\n","       fold_accuracy = []\n","       knn = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n","       # verificar cada uno de los modelos con validación cruzada.\n","       for train_fold, test_fold in cv.split(train):\n","          # División train test aleatoria\n","          f_train = train.loc[train_fold]\n","          f_test = train.loc[test_fold]\n","          # entrenamiento y ejecución del modelo\n","          knn.fit( X = f_train.drop(['count'], axis=1), \n","                               y = f_train['count'])\n","          y_pred = knn.predict(X = f_test.drop(['count'], axis = 1))\n","          # evaluación del modelo\n","          mae = mean_absolute_error(f_test['count'], y_pred)\n","          fold_accuracy.append(mae)\n","       total_scores.append(sum(fold_accuracy)/len(fold_accuracy))\n","   \n","   plt.plot(range(1,len(total_scores)+1), total_scores, \n","             marker='o', label=weights)\n","   print ('Min Value ' +  weights + \" : \" +  str(min(total_scores)) +\" (\" + str(np.argmin(total_scores) + 1) + \")\")\n","   plt.ylabel('MAE')      \n","    \n","\n","plt.legend()\n","plt.show() \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xj-T0YFK95v7"},"source":["# 2. Construcción y ejecución del modelo \n","\n"]},{"cell_type":"markdown","metadata":{"id":"YxzQici8RpSe"},"source":["Una vez que hemos identificado la mejor parametrización vamos a pasar a hacer una ejecución del modelo y vamos graficar sus resultados.\n","\n","Recordamos que al final del paso 1 hemos dividido en entrenamiento/tuneado y test"]},{"cell_type":"markdown","metadata":{"id":"IKOb2PaoR9jF"},"source":["Posteriormente, vamos a ejecutar el modelo con la mejor parametrización que hayamos obtenido anteriormente "]},{"cell_type":"code","metadata":{"id":"CT-gjUX1S9Em","cellView":"both"},"source":["# constructor\n","n_neighbors = 20\n","weights = 'distance'\n","knn = neighbors.KNeighborsRegressor(n_neighbors= n_neighbors, weights=weights) \n","# fit and predict\n","\n","knn.fit( X = train.drop(['count'], axis=1), y = train['count'])\n","y_pred = knn.predict(X = test.drop(['count'], axis = 1))\n","mae = mean_absolute_error(test['count'], y_pred)\n","print ('MAE', mae)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ahr3cQkiXNGa"},"source":["Y guardamos el fichero de resultados en nuestro disco."]},{"cell_type":"code","metadata":{"id":"3RCujicxWZTE"},"source":["# round the result and cast to int\n","import numpy as np\n","res = np.rint(y_pred) # round\n","res = res.astype(int) # cast to int\n","# generate output\n","output = pd.DataFrame({ 'date': test.index, 'result': res})\n","\n","\n","from google.colab import files\n","\n","with open('result.csv', 'w') as f:\n","  output.to_csv(f,  index = False)\n","  \n","\n","files.download('result.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7zxMMLgEY4f2"},"source":["Por último probamos visualizamos como ha quedado nuestra predicción con la realidad."]},{"cell_type":"code","metadata":{"id":"TxjU9Eiw9_J5"},"source":["\n","from sklearn.metrics import mean_absolute_error\n","\n","                    \n","# x axis for plotting\n","import numpy as np\n","xx = np.stack(i for i in range(test['count'].shape[0]))\n","plt.plot(xx, test['count'], c='r', label='data')\n","#plt.plot(xx, y, c='k', label='data')\n","plt.plot(xx, y_pred, c='g', label='prediction')\n","plt.axis('tight')\n","plt.legend()\n","plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors,\n","                                                                weights))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzBW0KpXmL_9"},"source":[""],"execution_count":null,"outputs":[]}]}